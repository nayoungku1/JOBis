import streamlit as st
import os
from dotenv import load_dotenv
from chatbot_core import ChatbotCore, MemoryHub
from agentA import run_analyzer
from build_faiss_db import build_or_update_vector_db

load_dotenv()
st.set_page_config(page_title="AI ë©´ì ‘ ì½”ì¹˜", layout="wide")
st.title("AI ë©´ì ‘ ì½”ì¹˜ ğŸ¤–")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "memory_hub" not in st.session_state:
    st.session_state["memory_hub"] = MemoryHub(
        interview_session={"chat_history": [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¨¼ì € ì‚¬ì´ë“œë°”ì— ì •ë³´ë¥¼ ì…ë ¥í•˜ê³  ìë£Œë¥¼ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”."}]}
    )
chatbot = ChatbotCore(memory=st.session_state.memory_hub)

with st.sidebar:
    st.header("1ï¸âƒ£ ë¶„ì„ ëŒ€ìƒ ì •ë³´")
    company_name = st.text_input("íšŒì‚¬ëª…", key="company_name")
    job_role = st.text_input("í¬ë§ ì§ë¬´", key="job_role")
    job_url = st.text_input("ì±„ìš© ê³µê³  URL (ì„ íƒ ì‚¬í•­)", key="job_url")

    st.divider()

    st.header("2ï¸âƒ£ ê°œì¸ ë§ì¶¤ ìë£Œ")
    personal_files = st.file_uploader(
        "ìê¸°ì†Œê°œì„œ, ì´ë ¥ì„œ ë“± ì—…ë¡œë“œ (.pdf, .docx)",
        type=['pdf', 'docx'],
        accept_multiple_files=True,
        key="personal_files_uploader"
    )

    st.divider()

    if st.button("ğŸš€ ë©´ì ‘ ì¤€ë¹„ ì‹œì‘!", use_container_width=True, type="primary"):
        if not st.session_state.company_name or not st.session_state.job_role:
            st.warning("íšŒì‚¬ëª…ê³¼ í¬ë§ ì§ë¬´ë¥¼ ë°˜ë“œì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not personal_files:
            st.warning("ê°œì¸ ë§ì¶¤ ë¶„ì„ì„ ìœ„í•´ í•˜ë‚˜ ì´ìƒì˜ ê°œì¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("1/3 | ìµœì‹  ê¸°ì—… ë° ì‹œì¥ ì •ë³´ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    report = run_analyzer(
                        company_name=st.session_state.company_name,
                        job_role=st.session_state.job_role,
                        url=st.session_state.job_url
                    )
                    chatbot.add_company_analysis(report)
                except Exception as e:
                    st.error(f"ê¸°ì—… ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    st.stop()
            
            with st.spinner("2/3 | ì—…ë¡œë“œëœ ê°œì¸ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    job_description_from_report = report 
                    chatbot.process_personal_documents(personal_files, job_description_from_report)
                except Exception as e:
                    st.error(f"ê°œì¸ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    st.stop()

            with st.spinner("3/3 | ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë§ì¶¤ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤..."):
                try:
                    chatbot.generate_interview_questions()
                    initial_message = (
                        f"âœ… **'{st.session_state.company_name}'({st.session_state.job_role})** ì§ë¬´ì— ëŒ€í•œ ëª¨ë“  ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n\n"
                        "**ìƒì„±ëœ ë§ì¶¤ ë©´ì ‘ ì§ˆë¬¸:**\n"
                    )
                    # for i, q in enumerate(chatbot.memory.interview_session.generated_questions[:5]):
                    #     initial_message += f"- {q}\n"
                    initial_message += "\në©´ì ‘ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? 'ì‹œì‘í• ê²Œ'ë¼ê³  ì…ë ¥í•´ì£¼ì„¸ìš”."
                    st.session_state.memory_hub.interview_session.chat_history = [
                        {"role": "assistant", "content": initial_message}
                    ]  # ì´ˆê¸°í™”í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
                except Exception as e:
                    st.error(f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    st.stop()
            st.rerun()

    st.divider()
    st.header("ğŸ“š ë‚´ë¶€ DB ê´€ë¦¬")
    db_files = st.file_uploader(
        "ë‚´ë¶€ ì§€ì‹ DBìš© íŒŒì¼ ì—…ë¡œë“œ (.pdf, .hwp, .csv, .zip ë“±)",
        accept_multiple_files=True,
        key="db_files_uploader"
    )
    if st.button("ë‚´ë¶€ DB ì—…ë°ì´íŠ¸", use_container_width=True):
        if db_files:
            data_dir = "data"
            os.makedirs(data_dir, exist_ok=True)
            with st.spinner('íŒŒì¼ì„ ì €ì¥í•˜ê³  ë²¡í„° DBë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤...'):
                for file in db_files:
                    with open(os.path.join(data_dir, file.name), "wb") as f:
                        f.write(file.getbuffer())
                try:
                    build_or_update_vector_db()
                    st.success(f"{len(db_files)}ê°œ íŒŒì¼ë¡œ DB ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
                except Exception as e:
                    st.error(f"DB ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.warning("ì—…ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# --- ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ ---
chat_container = st.container()
with chat_container:
    for msg in st.session_state.memory_hub.interview_session.chat_history:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

if user_input := st.chat_input("ë©´ì ‘ ì§ˆë¬¸ì— ë‹µë³€í•˜ê±°ë‚˜ ììœ ë¡­ê²Œ ì§ˆë¬¸í•´ë³´ì„¸ìš”..."):
    with chat_container:
        with st.chat_message("user"):
            st.markdown(user_input)
    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            # ì¤‘ë³µ ë©”ì‹œì§€ ë°©ì§€ë¥¼ ìœ„í•´ chat_historyë¥¼ ì§ì ‘ ìˆ˜ì •
            ai_response = chatbot.get_response(user_input)
            with chat_container:
                with st.chat_message("assistant"):
                    st.markdown(ai_response)
        except Exception as e:
            with chat_container:
                with st.chat_message("assistant"):
                    st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.rerun()