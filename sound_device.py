import os
from dotenv import load_dotenv
import sounddevice as sd
import numpy as np
import azure.cognitiveservices.speech as speechsdk
from langchain_openai import AzureChatOpenAI

# â”€â”€ 1) í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
speech_key     = os.getenv("SPEECH_KEY")
service_region = os.getenv("REGION")
if not speech_key or not service_region:
    raise RuntimeError(".envì— SPEECH_KEY, REGION ì„¤ì • í•„ìš”")

# â”€â”€ 2) ë…¹ìŒ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SAMPLE_RATE = 16000   # Azure ê¶Œì¥ 16kHz
CHANNELS    = 1       # ëª¨ë…¸
DTYPE       = 'int16' # 16ë¹„íŠ¸ ì •ìˆ˜

# â”€â”€ 3) ë…¹ìŒ ë²„í¼ ì¤€ë¹„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
frames = []  # ë…¹ìŒëœ ì¡°ê°ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

def callback(indata, frames_count, time_info, status):
    """InputStream ì—ì„œ ë¶ˆë¦¬ëŠ” í•¨ìˆ˜: indataëŠ” (frames_count, channels) ndarray"""
    if status:
        print(f"âš  ë…¹ìŒ ì—ëŸ¬: {status}")
    # ë³µì‚¬í•´ì„œ ì €ì¥ (sounddeviceëŠ” ë‚´ë¶€ ë²„í¼ë¥¼ ì¬ì‚¬ìš©í•¨)
    frames.append(indata.copy())

# â”€â”€ 4) ìŠ¤íŠ¸ë¦¼ ì—´ê³  ë…¹ìŒ ì‹œì‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
stream = sd.InputStream(
    samplerate=SAMPLE_RATE,
    channels=CHANNELS,
    dtype=DTYPE,
    callback=callback
)
stream.start()
print("â— ë…¹ìŒ ì¤‘â€¦ ë§ì´ ëë‚˜ë©´ ì—”í„°ë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”")
input()  # ì—”í„° ì…ë ¥ ëŒ€ê¸°
stream.stop()
stream.close()
print("âœ” ë…¹ìŒ ì¢…ë£Œ")

# â”€â”€ 5) í”„ë ˆì„ í•©ì¹˜ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
audio_data = np.concatenate(frames, axis=0)  # (ì´ìƒ˜í”Œìˆ˜, ì±„ë„) ndarray

# â”€â”€ 6) Azureë¡œ ë³´ë‚¼ ë°”ì´íŠ¸ ë³€í™˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
audio_bytes = audio_data.tobytes()
audio_format = speechsdk.audio.AudioStreamFormat(
    samples_per_second=SAMPLE_RATE,
    bits_per_sample=16,
    channels=CHANNELS
)
push_stream = speechsdk.audio.PushAudioInputStream(audio_format)
push_stream.write(audio_bytes)
push_stream.close()

# â”€â”€ 7) Azure Speech ì„¤ì • ë° ì¸ì‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
speech_config = speechsdk.SpeechConfig(
    subscription=speech_key,
    region=service_region
)
speech_config.speech_recognition_language = "ko-KR"

audio_config = speechsdk.audio.AudioConfig(stream=push_stream)
recognizer   = speechsdk.SpeechRecognizer(
    speech_config=speech_config,
    audio_config=audio_config
)

print("ğŸ”Š Azure Speech ì¸ì‹ ì¤‘â€¦")
result = recognizer.recognize_once()

# â”€â”€ 8) ê²°ê³¼ ì¶œë ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if result.reason == speechsdk.ResultReason.RecognizedSpeech:
    print("â–¶ ì¸ì‹ëœ í…ìŠ¤íŠ¸:", result.text)
elif result.reason == speechsdk.ResultReason.NoMatch:
    print("âš  ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    print("âŒ ì˜¤ë¥˜ ë°œìƒ:", result.reason)


def refine_text(background: str, question: str, transcript: str,
                model: str = "gpt-4o-mini",
                temperature: float = 0.2) -> str:
    """
    ë°°ê²½ì§€ì‹(background), ì§ˆë¬¸(question), STT í…ìŠ¤íŠ¸(transcript)ë¥¼
    ë°›ì•„ì„œ ê¹”ë”í•˜ê²Œ ë‹¤ë“¬ì€ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    system_prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ì–´ í…ìŠ¤íŠ¸ êµì •ê³¼ ë¬¸ì¥ ë‹¤ë“¬ê¸°ì— íŠ¹í™”ëœ LLMì…ë‹ˆë‹¤.
ë‹¤ìŒ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬, ì£¼ì–´ì§„ STT ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•œ ë¬¸ì¥ìœ¼ë¡œ ìˆ˜ì •í•´ ì£¼ì„¸ìš”.

ë°°ê²½ì§€ì‹:
{background}

ì§ˆë¬¸:
{question}

(STT ê²°ê³¼ì—ëŠ” ì˜¤íƒ€, ë„ì–´ì“°ê¸°, ë¬¸ì¥ë¶€í˜¸ ì˜¤ë¥˜ ë“±ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)
"""
    messages = [
        {"role": "system",  "content": system_prompt.strip()},
        {"role": "user",    "content": transcript.strip()}
    ]

    resp = AzureChatOpenAI.chat.completions.create(
        model = "gpt-4o-mini",
        messages=messages,
        temperature=temperature,
        max_tokens= max( len(transcript)*2,  256 )
    )
    return resp.choices[0].message.content.strip()


if __name__ == "__main__":
    # ì˜ˆì‹œ ì‚¬ìš©
    # background = "ì´ í†µí™”ëŠ” ê³ ê°ìƒë‹´ ì‹œë‚˜ë¦¬ì˜¤ì…ë‹ˆë‹¤."
    # question   = "ì¸ì‚¬ë§ì„ ì˜¬ë°”ë¥´ê²Œ êµì •í•´ ì£¼ì„¸ìš”."
    # transcript = "ì•ˆë…•í•˜í•˜ì„¸ìš” ê³ ê°ë‹˜ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”"
    # transcript = result.text
    
    # refined = refine_text(background, question, transcript)
    # print("ğŸ”„ ë‹¤ë“¬ì–´ì§„ ë¬¸ì¥:", refined)
    llm = AzureChatOpenAI(model = "gpt-4o-mini")
    query1 = result.text+"ì´ ë§ì„ ë¬¸ë²•ì— ë§ê²Œ ìˆ˜ì •í•´ì¤˜. ì˜ˆë¥¼ë“¤ë©´, ë–¨ë¦¼ì´ ìˆì–´ì„œ **ì•„ì•ˆë…•í•˜í•˜ì„¸ìš”** ë¼ë©´ **ì•ˆë…•í•˜ì„¸ìš”**ë¡œ ì¶œë ¥í•´ì¤˜. ì¶œë ¥ì€ ë°˜ë“œì‹œ ìˆ˜ì •í•œ ë§ë§Œ í•´. ì¶”ê°€ ì •ë³´ë¥¼ ë§ë¶™ì´ì§€ë§ˆ."
    print("ì¸ì‹ëœ í…ìŠ¤íŠ¸ : ", result.text)
    response = llm.invoke(query1)
    print("ìˆ˜ì •ëœ í…ìŠ¤íŠ¸: ", response.content)
    query2 = f"""ë„ˆëŠ” ë©´ì ‘ê´€ì´ì•¼. {result.text} ì´ ë§ê³¼ {response.content} ì´ ë§ì„ ë¹„êµì—ì„œ í›„ìì— ë¹„í•´ ì „ìì—ì„œ ê°œì„ í•´ì•¼í•  ë¶€ë¶„ë“¤ì„ ì¶œë ¥í•´ì¤˜. ì˜ˆë¥¼ë“¤ë©´, **ì•„ì•ˆë…•í•˜í•˜ì„¸ìš”**ì™€ **ì•ˆë…•í•˜ì„¸ìš”**ë¼ë©´ 'ë–¨ë¦¼ì´ ìˆìœ¼ë‹ˆ ì¤„ì´ì„¸ìš”'ë¡œ ì¶œë ¥í•´ì¤˜. ì¶œë ¥ì€ ë§í•˜ëŠ” ì‚¬ëŒ ê¸°ì¤€ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ í•´"""
    res = llm.invoke(query2)
    print("í”¼ë“œë°±: ", res.content)